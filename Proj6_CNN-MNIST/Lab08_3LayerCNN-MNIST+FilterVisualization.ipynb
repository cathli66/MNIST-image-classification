{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "binary-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "# from keras.datasets import mnist\n",
    "# from keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Fixing shape of data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surgical-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        3200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        200768    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 410,198\n",
      "Trainable params: 410,070\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(64, kernel_size=(7, 7), strides=(1, 1), padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
    "        layers.Conv2D(64, kernel_size=(7, 7), strides=(1, 1), padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
    "        layers.Conv2D(64, kernel_size=(5, 5), strides=(1, 1), padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stainless-conviction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "54000/54000 [==============================] - 173s 3ms/sample - loss: 1.4794 - accuracy: 0.9021 - val_loss: 1.3941 - val_accuracy: 0.9095\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 166s 3ms/sample - loss: 1.4184 - accuracy: 0.9076 - val_loss: 1.5226 - val_accuracy: 0.9011\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 168s 3ms/sample - loss: 1.4488 - accuracy: 0.9055 - val_loss: 1.4120 - val_accuracy: 0.9082\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 181s 3ms/sample - loss: 1.4027 - accuracy: 0.9088 - val_loss: 1.3996 - val_accuracy: 0.9091\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 178s 3ms/sample - loss: 1.3803 - accuracy: 0.9104 - val_loss: 1.3859 - val_accuracy: 0.9101\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 178s 3ms/sample - loss: 1.3776 - accuracy: 0.9106 - val_loss: 1.3907 - val_accuracy: 0.9098\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 176s 3ms/sample - loss: 1.3772 - accuracy: 0.9107 - val_loss: 1.3854 - val_accuracy: 0.9102\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 187s 3ms/sample - loss: 1.3759 - accuracy: 0.9108 - val_loss: 1.3852 - val_accuracy: 0.9101\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 191s 4ms/sample - loss: 1.3938 - accuracy: 0.9095 - val_loss: 1.3854 - val_accuracy: 0.9102\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 195s 4ms/sample - loss: 1.3683 - accuracy: 0.9109 - val_loss: 1.2645 - val_accuracy: 0.9173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f86b6e72b90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "trained-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9171802\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter visualization\n",
    "pyplot.rcParams['figure.max_open_warning'] = 100\n",
    "pyplot.close('all')\n",
    "for n in [0, 4]:\n",
    "    filters, biases = model.layers[n].get_weights()\n",
    "    print(layer[n].name, filters.shape)\n",
    "\n",
    "    f_min, f_max = filters.min(), filters.max()\n",
    "    filters = (filters - f_min) / (f_max - f_min)\n",
    "\n",
    "    n_filters, ix = 64, 1\n",
    "    ftr = 0\n",
    "    pyplot.figure(figsize = (10,70))\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            ftr = i*8 + j\n",
    "            f = filters[:, :, :, ftr]\n",
    "            ax = pyplot.subplot(n_filters, 8, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            \n",
    "            pyplot.imshow(f[:, :, 0], cmap='gray')\n",
    "            ix += 1\n",
    "    # show the figure\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-substitute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
